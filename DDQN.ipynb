{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD , Adam\n",
    "import tensorflow as tf\n",
    "import skimage\n",
    "from skimage import color, exposure, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-14 08:54:57,711] Making new env: PongDeterministic-v4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ..., \n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       [[109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        ..., \n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       [[109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        ..., \n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       ..., \n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ..., \n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]],\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ..., \n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]],\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ..., \n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('PongDeterministic-v4')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = env.action_space.n # number of valid actions\n",
    "GAMMA = 0.99 # decay rate of past observations\n",
    "OBSERVATION = 10000. # timesteps to observe before training\n",
    "EXPLORE = 300000. # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.01 # final value of epsilon\n",
    "INITIAL_EPSILON = 1 # starting value of epsilon\n",
    "REPLAY_MEMORY = 20000 # number of previous transitions to remember\n",
    "BATCH = 32 # size of minibatch\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "img_rows , img_cols = 80, 80\n",
    "#Convert image into Black and white\n",
    "img_channels = 1 #We stack 4 frames\n",
    "\n",
    "MODEL_NAME = \"breakout_deterministic_model_atari_ddqn_more_explore.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    initializer = initializers.RandomNormal(mean=0.0, stddev=0.005, seed=None)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 8, 8, subsample=(4, 4), border_mode='same',input_shape=(img_rows,img_cols,img_channels), kernel_initializer=initializer, bias_initializer='zeros'))  #80*80*4\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 4, 4, subsample=(2, 2), border_mode='same', kernel_initializer=initializer, bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode='same', kernel_initializer=initializer, bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_initializer=initializer, bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(ACTIONS, kernel_initializer=initializer, bias_initializer='zeros'))\n",
    "\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    print(\"We finish building the model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapped_Game:\n",
    "    def __init__(self, game):\n",
    "        self.game = game\n",
    "        self.game.reset()\n",
    "    def step(self, action):\n",
    "        ns, r, d, _ = self.game.step(action)\n",
    "        if d:\n",
    "            self.game.reset()\n",
    "        return ns, r, d, _\n",
    "    def reset(self):\n",
    "        self.game.reset()\n",
    "    def render(self):\n",
    "        self.game.render()\n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model(model):\n",
    "    \"\"\"Returns a copy of a keras model.\"\"\"\n",
    "    model.save('tmp_model')\n",
    "    return keras.models.load_model('tmp_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_session(model, target_model):\n",
    "    from keras import backend as K\n",
    "    model_path = 'tmp_model_name_ddqn'\n",
    "    model.save(model_path)\n",
    "    del model\n",
    "    target_model_path = 'tmp_target_model_name_ddqn'\n",
    "    target_model.save(target_model_path)\n",
    "    del target_model\n",
    "    K.clear_session()\n",
    "    model = keras.models.load_model(model_path)\n",
    "    target_model = keras.models.load_model(target_model_path)\n",
    "    return model, target_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, env):\n",
    "    \n",
    "    target_model = copy_model(model)\n",
    "    \n",
    "    #init replay memory\n",
    "    M = deque()\n",
    " \n",
    "    env.reset()\n",
    "    next_state, reward, done, _ = env.step(0)\n",
    "\n",
    "    x_t = skimage.color.rgb2gray(next_state)\n",
    "    x_t = skimage.transform.resize(x_t,(80,80))\n",
    "    x_t = skimage.exposure.rescale_intensity(x_t,out_range=(0,255))\n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])\n",
    "\n",
    "    OBSERVE = OBSERVATION\n",
    "    epsilon = INITIAL_EPSILON\n",
    "\n",
    "    prev_done = False\n",
    "    \n",
    "    t = 0\n",
    "    while(True):\n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "        r_t = 0\n",
    "        a_t = 0\n",
    "        \n",
    "        # explore\n",
    "        if random.random() <= epsilon or t < OBSERVE:\n",
    "            a_t = random.randrange(ACTIONS)\n",
    "        # exploit\n",
    "        else:\n",
    "            q = model.predict(s_t)\n",
    "            policy_max_Q = np.argmax(q)\n",
    "            a_t = policy_max_Q\n",
    "            #print(a_t)\n",
    "        # move toward more exploitation\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "        \n",
    "        if prev_done:\n",
    "            next_state, reward, done, _ = env.step(0)\n",
    "            x_t = skimage.color.rgb2gray(next_state)\n",
    "            x_t = skimage.transform.resize(x_t,(80,80))\n",
    "            x_t = skimage.exposure.rescale_intensity(x_t,out_range=(0,255))\n",
    "\n",
    "            s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "            s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])\n",
    "        \n",
    "        # conduct new state\n",
    "        next_state, r_t, done, _ = env.step(a_t)\n",
    "        #env.render()\n",
    "        \n",
    "        prev_done = done\n",
    "        \n",
    "        #env.render()\n",
    "        x_t1 = skimage.color.rgb2gray(next_state)\n",
    "        x_t1 = skimage.transform.resize(x_t1,(80,80))\n",
    "        x_t1 = skimage.exposure.rescale_intensity(x_t1,out_range=(0,255))\n",
    "\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x80x80x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3)\n",
    "\n",
    "        # save in replay memory\n",
    "        M.append((s_t, a_t, r_t, s_t1, done))\n",
    "        if (len(M) > REPLAY_MEMORY):\n",
    "            M.popleft()\n",
    "\n",
    "        if t > OBSERVE:\n",
    "            minibatch = random.sample(M, BATCH)\n",
    "            inputs = np.zeros((BATCH, s_t.shape[1], s_t.shape[2], s_t.shape[3]))\n",
    "            targets = np.zeros((BATCH, ACTIONS))\n",
    "\n",
    "            # experience replay\n",
    "            for i in range(0, BATCH):\n",
    "                state_t = minibatch[i][0]\n",
    "                action_t = minibatch[i][1]\n",
    "                reward_t = minibatch[i][2]\n",
    "                state_t1 = minibatch[i][3]\n",
    "                done_t = minibatch[i][4]\n",
    "\n",
    "                inputs[i] = state_t\n",
    "                targets[i] = target_model.predict(state_t)\n",
    "                # DDQN formula\n",
    "                # Q-Target = r + γQ(s’,argmax(Q(s’,a,ϴ),ϴ’))\n",
    "                Q_sa = target_model.predict(state_t1)\n",
    "                if done_t:\n",
    "                    targets[i, action_t] = reward_t\n",
    "                else:\n",
    "                    targets[i, action_t] = reward_t + GAMMA * Q_sa[0][action_t]\n",
    "\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "\n",
    "        s_t = s_t1\n",
    "        t += 1\n",
    "\n",
    "        # save progress every 1000 iterations\n",
    "        if t % 1000 == 0:\n",
    "            print(\"Now we save model\")\n",
    "            model.save_weights(MODEL_NAME, overwrite=True)\n",
    "            with open(\"model.json\", \"w\") as outfile:\n",
    "                json.dump(model.to_json(), outfile)\n",
    "        \n",
    "        if t % 15000 == 0:\n",
    "            model, target_model = clear_session(model, target_model)\n",
    "        if t % 500 == 0:\n",
    "            target_model = copy_model(model)\n",
    "\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "        if t % 1000 == 0 or r_t > 0.0:\n",
    "            print(\"TIMESTEP\", t, \"/ STATE\", state, \\\n",
    "                \"/ EPSILON\", epsilon, \"/ ACTION\", a_t, \"/ REWARD\", r_t, \\\n",
    "                \"/ Q_MAX \" , np.max(Q_sa), \"/ Loss \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, env):\n",
    "    print (\"Now we test model\")\n",
    "    #model.load_weights(MODEL_NAME)\n",
    "    #adam = Adam(lr=LEARNING_RATE)\n",
    "    #model.compile(loss='mse',optimizer=adam)\n",
    "    #print (\"Weight load successfully\")\n",
    "    env.reset()\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(0)\n",
    "    \n",
    "    x_t = skimage.color.rgb2gray(next_state)\n",
    "    x_t = skimage.transform.resize(x_t,(80,80))\n",
    "    x_t = skimage.exposure.rescale_intensity(x_t,out_range=(0,255))\n",
    "    x_t = x_t.reshape((1, 80, 80, 1))\n",
    "    \n",
    "    s_t = x_t - x_t\n",
    "    #s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])\n",
    "    print(s_t.shape)\n",
    "    for i in range(500):\n",
    "        q = model.predict(s_t)\n",
    "        policy_max_Q = np.argmax(q)\n",
    "        a_t = policy_max_Q\n",
    "        #print(a_t)\n",
    "        next_state, r_t, done, _ = env.step(a_t)\n",
    "        x_t1 = skimage.color.rgb2gray(next_state)\n",
    "        x_t1 = skimage.transform.resize(x_t1,(80,80))\n",
    "        x_t1 = skimage.exposure.rescale_intensity(x_t1,out_range=(0,255))\n",
    "        x_t1 = x_t1.reshape((1, 80, 80, 1))\n",
    "        #x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x80x80x1\n",
    "        #s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3)\n",
    "        s_t1 = x_t1 - x_t\n",
    "\n",
    "        s_t = s_t1\n",
    "        x_t = x_t1\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(a_t)\n",
    "        env.render()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We finish building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (8, 8), input_shape=(80, 80, 1..., padding=\"same\", strides=(4, 4), kernel_initializer=<keras.ini..., bias_initializer=\"zeros\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), padding=\"same\", strides=(2, 2), kernel_initializer=<keras.ini..., bias_initializer=\"zeros\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", strides=(1, 1), kernel_initializer=<keras.ini..., bias_initializer=\"zeros\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "#model.load_weights('1100000_iters_breakout_deterministic_model_atari_ddqn_more_explore.h5')\n",
    "model.load_weights('backup_pong_lr-4/250000_iters_pdv4_ddqn_lr-4_tmr_100_after_500000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_model(model, Wrapped_Game(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we test model\n",
      "(1, 80, 80, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "test_model(model, Wrapped_Game(env))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
